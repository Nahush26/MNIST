{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "973ab55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266591ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is GeForce 940MX\n",
      "\n",
      " cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(torch.cuda.is_available()):\n",
    "  print(\"The device is \" + torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"Using cpu no gpu available\")\n",
    "print('\\n',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dbbc229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\leleg\\anaconda3\\envs\\pytorchml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train = True ,download =  True, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307, ), (0.3081, ))]))\n",
    "test = datasets.MNIST(\"\",train = False ,download = True, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307, ), (0.3081, ))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0de8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "846252d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split,DataLoader\n",
    "train,val = random_split(train, [55000,5000])\n",
    "train_loader = DataLoader(train,batch_size = 64)\n",
    "val_loader = DataLoader(val,batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9081b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb4fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c10722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9503c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bddad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6439a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipper(nn.Module):\n",
    "    def __init__(self,width):\n",
    "        super(skipper,self).__init__()\n",
    "        #making a res block using sequential inside module hehe\n",
    "        self.resb1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = width[0] , \n",
    "                  out_channels = width[1], \n",
    "                  kernel_size= (3,3),\n",
    "                  stride = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = width[1],\n",
    "                  out_channels = width[2],\n",
    "                  kernel_size = (3,3),\n",
    "                  stride = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[2]),\n",
    "        nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "                  \n",
    "        )\n",
    "        self.skip = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = width[0],\n",
    "                  out_channels = width[2],\n",
    "                  kernel_size = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[2]),\n",
    "        nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        #cut = x\n",
    "        out1 = self.resb1(x)\n",
    "        #print(out1.shape)\n",
    "        out2 = self.skip(x)\n",
    "        x = F.relu(out1+out2)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f8ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network,self).__init__()\n",
    "        self.block1 =  skipper(width= [1,16,32])\n",
    "        #self.reduce = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "        self.block2 =  skipper(width= [32,64,128])\n",
    "        self.fc1    =  nn.Linear(128*7*7,200)\n",
    "        self.fc2    =  nn.Linear(200,10)\n",
    "        #self.bn1    =  nn.BatchNorm1d(200)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.block1(x)\n",
    "        #print(out.shape)\n",
    "        #out = self.reduce(out)\n",
    "        out = self.block2(out)\n",
    "        #out = self.reduce(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        #out = self.bn1(out)\n",
    "        score = self.fc2(out)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7871807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec4136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part(model, optimizer,scheduler_f, epochs=1):\n",
    "    losses =[]\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        avg = 0\n",
    "        i = 0\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            #scores = scores.reshape(y.shape[1])\n",
    "            #print(scores.shape,x.shape,y.shape)\n",
    "            #break\n",
    "            loss = metric(scores, y)\n",
    "           \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "            loss.backward()\n",
    "             \n",
    "        \n",
    "            optimizer.step()\n",
    "            #scheduler_f.step()\n",
    "            avg+=float(loss)\n",
    "            i+=1\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part(val_loader, model)\n",
    "                print()\n",
    "        scheduler_f.step()\n",
    "        print('Epoch-{0} lr: {1}'.format(e, optimizer.param_groups[0]['lr']))\n",
    "        losses.append(avg/i)\n",
    "    return losses\n",
    "        #break\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d637033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the layers of the model : \n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
      "              ReLU-3           [-1, 16, 28, 28]               0\n",
      "            Conv2d-4           [-1, 32, 28, 28]           4,640\n",
      "       BatchNorm2d-5           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-6           [-1, 32, 14, 14]               0\n",
      "            Conv2d-7           [-1, 32, 28, 28]              64\n",
      "       BatchNorm2d-8           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-9           [-1, 32, 14, 14]               0\n",
      "          skipper-10           [-1, 32, 14, 14]               0\n",
      "           Conv2d-11           [-1, 64, 14, 14]          18,496\n",
      "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
      "             ReLU-13           [-1, 64, 14, 14]               0\n",
      "           Conv2d-14          [-1, 128, 14, 14]          73,856\n",
      "      BatchNorm2d-15          [-1, 128, 14, 14]             256\n",
      "        MaxPool2d-16            [-1, 128, 7, 7]               0\n",
      "           Conv2d-17          [-1, 128, 14, 14]           4,224\n",
      "      BatchNorm2d-18          [-1, 128, 14, 14]             256\n",
      "        MaxPool2d-19            [-1, 128, 7, 7]               0\n",
      "          skipper-20            [-1, 128, 7, 7]               0\n",
      "           Linear-21                  [-1, 200]       1,254,600\n",
      "           Linear-22                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 1,358,850\n",
      "Trainable params: 1,358,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.39\n",
      "Params size (MB): 5.18\n",
      "Estimated Total Size (MB): 7.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = network()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size = 3,gamma = 0.3)\n",
    "print(\"Summary of the layers of the model : \\n\\n\")\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82888226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3465\n",
      "Got 480 / 5000 correct (9.60)\n",
      "\n",
      "Iteration 200, loss = 0.0364\n",
      "Got 4816 / 5000 correct (96.32)\n",
      "\n",
      "Iteration 400, loss = 0.0735\n",
      "Got 4803 / 5000 correct (96.06)\n",
      "\n",
      "Iteration 600, loss = 0.1304\n",
      "Got 4853 / 5000 correct (97.06)\n",
      "\n",
      "Iteration 800, loss = 0.0901\n",
      "Got 4871 / 5000 correct (97.42)\n",
      "\n",
      "Epoch-0 lr: 0.001\n",
      "Iteration 0, loss = 0.0138\n",
      "Got 4892 / 5000 correct (97.84)\n",
      "\n",
      "Iteration 200, loss = 0.0030\n",
      "Got 4922 / 5000 correct (98.44)\n",
      "\n",
      "Iteration 400, loss = 0.0527\n",
      "Got 4901 / 5000 correct (98.02)\n",
      "\n",
      "Iteration 600, loss = 0.1298\n",
      "Got 4898 / 5000 correct (97.96)\n",
      "\n",
      "Iteration 800, loss = 0.0564\n",
      "Got 4930 / 5000 correct (98.60)\n",
      "\n",
      "Epoch-1 lr: 0.001\n",
      "Iteration 0, loss = 0.0092\n",
      "Got 4913 / 5000 correct (98.26)\n",
      "\n",
      "Iteration 200, loss = 0.0010\n",
      "Got 4921 / 5000 correct (98.42)\n",
      "\n",
      "Iteration 400, loss = 0.0431\n",
      "Got 4911 / 5000 correct (98.22)\n",
      "\n",
      "Iteration 600, loss = 0.0824\n",
      "Got 4943 / 5000 correct (98.86)\n",
      "\n",
      "Iteration 800, loss = 0.0051\n",
      "Got 4942 / 5000 correct (98.84)\n",
      "\n",
      "Epoch-2 lr: 0.0003\n",
      "Iteration 0, loss = 0.0064\n",
      "Got 4940 / 5000 correct (98.80)\n",
      "\n",
      "Iteration 200, loss = 0.0041\n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 400, loss = 0.0010\n",
      "Got 4955 / 5000 correct (99.10)\n",
      "\n",
      "Iteration 600, loss = 0.0679\n",
      "Got 4960 / 5000 correct (99.20)\n",
      "\n",
      "Iteration 800, loss = 0.0035\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Epoch-3 lr: 0.0003\n",
      "Iteration 0, loss = 0.0155\n",
      "Got 4974 / 5000 correct (99.48)\n",
      "\n",
      "Iteration 200, loss = 0.0020\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Iteration 400, loss = 0.0005\n",
      "Got 4958 / 5000 correct (99.16)\n",
      "\n",
      "Iteration 600, loss = 0.0677\n",
      "Got 4966 / 5000 correct (99.32)\n",
      "\n",
      "Iteration 800, loss = 0.0048\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Epoch-4 lr: 0.0003\n",
      "Iteration 0, loss = 0.0012\n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 200, loss = 0.0031\n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 400, loss = 0.0005\n",
      "Got 4955 / 5000 correct (99.10)\n",
      "\n",
      "Iteration 600, loss = 0.0606\n",
      "Got 4963 / 5000 correct (99.26)\n",
      "\n",
      "Iteration 800, loss = 0.0041\n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Epoch-5 lr: 8.999999999999999e-05\n",
      "Iteration 0, loss = 0.0013\n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 200, loss = 0.0028\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Iteration 400, loss = 0.0003\n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 600, loss = 0.0201\n",
      "Got 4975 / 5000 correct (99.50)\n",
      "\n",
      "Iteration 800, loss = 0.0011\n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Epoch-6 lr: 8.999999999999999e-05\n",
      "Iteration 0, loss = 0.0015\n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 200, loss = 0.0029\n",
      "Got 4976 / 5000 correct (99.52)\n",
      "\n",
      "Iteration 400, loss = 0.0003\n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 600, loss = 0.0200\n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 800, loss = 0.0008\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Epoch-7 lr: 8.999999999999999e-05\n",
      "Iteration 0, loss = 0.0015\n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 200, loss = 0.0019\n",
      "Got 4975 / 5000 correct (99.50)\n",
      "\n",
      "Iteration 400, loss = 0.0002\n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 600, loss = 0.0156\n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 800, loss = 0.0008\n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Epoch-8 lr: 2.6999999999999996e-05\n",
      "Iteration 0, loss = 0.0009\n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Iteration 200, loss = 0.0009\n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 400, loss = 0.0001\n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 600, loss = 0.0032\n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 800, loss = 0.0005\n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Epoch-9 lr: 2.6999999999999996e-05\n"
     ]
    }
   ],
   "source": [
    "losses = train_part(model, optimizer,scheduler_f = scheduler,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e6ed626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost v/s Epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAifUlEQVR4nO3de3hc9X3n8fd3ZnS3biPLd2MNYC4mKcbIMpSSFEi6Nm0xaZsuPC0h3fTxegvh0mRT2qf7NLvPdp9sFhKSlkJJQkraFEK4FLd1QyjNhaQESzY3X3BwbWPLki0ZW5Jvuozmu3/MkRmPZWtkjXQkzef1PHpmzu/8zpzvGbA+Or8zc37m7oiISOGJhF2AiIiEQwEgIlKgFAAiIgVKASAiUqAUACIiBSoWdgGjMXPmTG9oaAi7DBGRKWXjxo0H3b0+u31KBUBDQwMtLS1hlyEiMqWY2bvDtWsISESkQCkAREQKlAJARKRAKQBERAqUAkBEpEApAERECpQCQESkQBVEAPxgewd/9cMdYZchIjKp5BQAZrbSzLab2Q4zu2+Y9ZeY2Stm1mdmn81ov9jMXs/46TGze4J1nzezfRnrbszbUWX59x0HefDFd+gdGByvXYiITDkjBoCZRYGHgFXAEuBWM1uS1e0QcBdwf2aju29396XuvhS4EjgOPJfR5ctD6919/bkfxtk1JeroH0zxxt6u8dqFiMiUk8sZQBOww913uns/8CSwOrODu3e4ezMwcJbXuQH4D3cf9ivJ46lxUS0AzbsPTfSuRUQmrVwCYD6wN2O5NWgbrVuAJ7La7jSzN83sMTOrHW4jM1tjZi1m1tLZ2XkOu4XaimIunl3Jq7sUACIiQ3IJABumbVQTCZtZMXAT8N2M5oeBC4ClQDvwwHDbuvuj7t7o7o319afdzC5nTYk4m949THIwdc6vISIyneQSAK3AwozlBUDbKPezCtjk7geGGtz9gLsPunsK+BrpoaZxszwR51j/IFvbe8ZzNyIiU0YuAdAMLDazRPCX/C3AulHu51ayhn/MbG7G4seAzaN8zVFpaogDsEHDQCIiQA4B4O5J4E7gBWAb8JS7bzGztWa2FsDM5phZK/CHwJ+aWauZVQXryoGPAs9mvfQXzewtM3sTuA64N29HNYw51aUsqivXdQARkUBOE8IEH9Fcn9X2SMbz/aSHhobb9jhQN0z7baOqNA+WN8R5adsBUiknEhnu0oaISOEoiG8CD2lKxDl8fIAdnUfDLkVEJHQFFQArEunrABoGEhEpsAA4L17OrMoSmhUAIiKFFQBmRlMizoZdh3Af1VcZRESmnYIKAEgPA+3v6aX18ImwSxERCVXBBcByXQcQEQEKMAAumlVJdVkRG3a9F3YpIiKhKrgAiESM5Q1xmncfDrsUEZFQFVwAADQlatl18BgdPb1hlyIiEpoCDYD0F5M3aH4AESlgBRkAl82roqwoqu8DiEhBK8gAKIpGuHJRrT4JJCIFrSADANL3Bdp+4Ajdx882i6WIyPRVsAGwvCGOO7S8q7MAESlMBRsAV5xXQ1HUNEGMiBSsgg2A0qIoly+o0SeBRKRgFWwAQPq2EG+1dnO8Pxl2KSIiE66gA6ApESeZcl7b0xV2KSIiE66gA+DKRbVETBPFi0hhyikAzGylmW03sx1mdt8w6y8xs1fMrM/MPpu1bncw+fvrZtaS0R43sxfN7J3gsXbshzM6VaVFXDq3SgEgIgVpxAAwsyjwELAKWALcamZLsrodAu4C7j/Dy1zn7kvdvTGj7T7gJXdfDLwULE+4pkScTXsO059MhbF7EZHQ5HIG0ATscPed7t4PPAmszuzg7h3u3gyM5ltVq4HHg+ePAzePYtu8WZGI05dM8da+7jB2LyISmlwCYD6wN2O5NWjLlQPfN7ONZrYmo322u7cDBI+zhtvYzNaYWYuZtXR2do5it7lpbEhPEKNhIBEpNLkEgA3TNpoJda9x92Wkh5DuMLMPjWJb3P1Rd29098b6+vrRbJqTmTNKuKC+QhPEiEjBySUAWoGFGcsLgLZcd+DubcFjB/Ac6SElgANmNhcgeOzI9TXzrSlRR8u7hxlMaaJ4ESkcuQRAM7DYzBJmVgzcAqzL5cXNrMLMKoeeA78CbA5WrwNuD57fDjw/msLzqSlRy5HeJG/v7wmrBBGRCRcbqYO7J83sTuAFIAo85u5bzGxtsP4RM5sDtABVQMrM7iH9iaGZwHNmNrSvv3f37wUv/QXgKTP7FLAH+Hhej2wUhiaIad51iMvmVYdVhojIhBoxAADcfT2wPqvtkYzn+0kPDWXrAS4/w2u+B9yQc6XjaH5NGfNrytiw+xCfvCYRdjkiIhOioL8JnKkpEWfDrkO46zqAiBQGBUCgKRHn4NF+dh08FnYpIiITQgEQWK7vA4hIgVEABC6or6CuolgBICIFQwEQMLP0dQBNECMiBUIBkGF5Q5zWwyfY13Ui7FJERMadAiBDUyJ9HaBZw0AiUgAUABkunVtFZUlMw0AiUhAUABmiEePKhlpdCBaRgqAAyNKUiLOj4yjvHe0LuxQRkXGlAMiyYug6wO7DIVciIjK+FABZPji/hpJYRMNAIjLtKQCyFMciXHFeDc26ECwi05wCYBhNDXG2tHVzpHc0UxyLiEwtCoBhNCXqSDlsfFfXAURk+lIADGPZohpiEdMwkIhMawqAYZQXx7hsfrUuBIvItKYAOIMViThv7O2md2Aw7FJERMaFAuAMmhri9A+meGNvV9iliIiMi5wCwMxWmtl2M9thZvcNs/4SM3vFzPrM7LMZ7QvN7Admts3MtpjZ3RnrPm9m+8zs9eDnxvwcUn40NtQCmiBGRKavESeFN7Mo8BDwUaAVaDazde6+NaPbIeAu4OaszZPAZ9x9k5lVAhvN7MWMbb/s7veP9SDGQ015MZfMqdSN4URk2srlDKAJ2OHuO929H3gSWJ3Zwd073L0ZGMhqb3f3TcHzI8A2YH5eKp8ATYk4G989THIwFXYpIiJ5l0sAzAf2Ziy3cg6/xM2sAbgCeDWj+U4ze9PMHjOz2jNst8bMWsyspbOzc7S7HZPlDXGO9w+ypa1nQvcrIjIRcgkAG6bNR7MTM5sBPAPc4+5Dv00fBi4AlgLtwAPDbevuj7p7o7s31tfXj2a3Y3ZyghgNA4nINJRLALQCCzOWFwBtue7AzIpI//L/trs/O9Tu7gfcfdDdU8DXSA81TSqzq0ppqCvnVV0IFpFpKJcAaAYWm1nCzIqBW4B1uby4mRnwDWCbu38pa93cjMWPAZtzK3liLW+I07z7EKnUqE56REQmvREDwN2TwJ3AC6Qv4j7l7lvMbK2ZrQUwszlm1gr8IfCnZtZqZlXANcBtwPXDfNzzi2b2lpm9CVwH3Jv/wxu7pkScruMD7Og8GnYpIiJ5NeLHQAHcfT2wPqvtkYzn+0kPDWX7CcNfQ8Ddb8u9zPCsSNQB8OquQ1w0uzLkakRE8kffBB7BwngZs6tK9IUwEZl2FAAjMDOaEnU07zqEu64DiMj0oQDIQVNDLft7etl76ETYpYiI5I0CIAdNJ68DvBdyJSIi+aMAyMHiWTOoKS/SF8JEZFpRAOQgEjEaF8V1IVhEphUFQI5WJOLsfu84HT29YZciIpIXCoAcDd0XSLeHFpHpQgGQo8vmVVFeHNUwkIhMGwqAHMWiEa5cVKsAEJFpQwEwCk0NcbYfOELX8f6wSxERGTMFwCgsT8Rxh5bdh8MuRURkzBQAo7B0YQ3F0Yi+DyAi04ICYBRKi6JcvrBaE8SIyLSgABil5Q1xNu/r5nh/MuxSRETGRAEwSk2JOMmU89qerrBLEREZEwXAKF25qJaIoWEgEZnyFACjVFlaxJJ5VTQrAERkilMAnIOmhjo27TlMfzIVdikiIucspwAws5Vmtt3MdpjZfcOsv8TMXjGzPjP7bC7bmlnczF40s3eCx9qxH87EaErU0pdM8da+rrBLERE5ZyMGgJlFgYeAVcAS4FYzW5LV7RBwF3D/KLa9D3jJ3RcDLwXLU8LyhuDGcLv0hTARmbpyOQNoAna4+0537weeBFZndnD3DndvBgZGse1q4PHg+ePAzed2CBOvbkYJF86awQbNECYiU1guATAf2Jux3Bq05eJs285293aA4HHWcC9gZmvMrMXMWjo7O3Pc7fhb3hCnZfdhBlOaKF5EpqZcAsCGacv1t95Ytk13dn/U3RvdvbG+vn40m46rFYk4R/qSvL2/J+xSRETOSS4B0AoszFheALTl+Ppn2/aAmc0FCB47cnzNSeHkBDH6OKiITFG5BEAzsNjMEmZWDNwCrMvx9c+27Trg9uD57cDzuZcdvnk1ZcyvKVMAiMiUFRupg7snzexO4AUgCjzm7lvMbG2w/hEzmwO0AFVAyszuAZa4e89w2wYv/QXgKTP7FLAH+Hiej23crUjE+fE7nbg7ZsONdomITF4jBgCAu68H1me1PZLxfD/p4Z2ctg3a3wNuGE2xk01TIs6zr+1j58FjXFA/I+xyRERGRd8EHoPlwXUA3RZCRKYiBcAYnD+zgpkzinUdQESmJAXAGJgZTYm47gwqIlOSAmCMljfE2dd1gn1dJ8IuRURkVBQAY9Sk6wAiMkUpAMbokjlVVJbGNAwkIlOOAmCMohGjcVEtzbsVACIytSgA8qApUceOjqMcPNoXdikiIjlTAORBUyI9l02LzgJEZApRAOTBB+fXUBKLaIIYEZlSFAB5UByLsOy8Wjbs1gQxIjJ1KADyZHkizta2Ho70Zk+KJiIyOSkA8mRFIk7KYeO7GgYSkalBAZAnV5xXQyxiui+QiEwZCoA8KS+O8YH51fo+gIhMGQqAPFqRiPPG3m56BwbDLkVEZEQKgDxqSsTpH0zx+t6usEsRERmRAiCPGhfFMdON4URkalAA5FF1eREXz65kg64DiMgUkFMAmNlKM9tuZjvM7L5h1puZfTVY/6aZLQvaLzaz1zN+eoIJ4zGzz5vZvox1N+b1yEKyIhFn47uHSQ6mwi5FROSsRgwAM4sCDwGrgCXArWa2JKvbKmBx8LMGeBjA3be7+1J3XwpcCRwHnsvY7stD64PJ46e85Yk4x/sH2dLWE3YpIiJnlcsZQBOww913uns/8CSwOqvPauBbnvYzoMbM5mb1uQH4D3d/d8xVT2JNDekJYvR9ABGZ7HIJgPnA3ozl1qBttH1uAZ7IarszGDJ6zMxqh9u5ma0xsxYza+ns7Myh3HDNqiolMbNC1wFEZNLLJQBsmDYfTR8zKwZuAr6bsf5h4AJgKdAOPDDczt39UXdvdPfG+vr6HMoN3/KG9AQxqVT22yQiMnnkEgCtwMKM5QVA2yj7rAI2ufuBoQZ3P+Dug+6eAr5GeqhpWmhK1NF1fIB3Oo6GXYqIyBnlEgDNwGIzSwR/yd8CrMvqsw74RPBpoKuAbndvz1h/K1nDP1nXCD4GbB519ZPUyesAGgYSkUlsxABw9yRwJ/ACsA14yt23mNlaM1sbdFsP7AR2kP5r/g+GtjezcuCjwLNZL/1FM3vLzN4ErgPuHevBTBYL42XMqSrVhWARmdRiuXQKPqK5PqvtkYznDtxxhm2PA3XDtN82qkqnEDOjKRHn1V3v4e6YDXeJREQkXPom8DhZnohzoKePvYdOhF2KiMiwFADjZEUifR3g1V2aJlJEJicFwDi5sH4GteVFug4gIpOWAmCcRCJGY0NcE8SIyKSlABhHKxJxdr93nAM9vWGXIiJyGgXAOGpK6L5AIjJ5KQDG0ZK5VVQURzUMJCKTkgJgHMWiEZYtqtUZgIhMSgqAcbYiEWf7gSN0He8PuxQRkVMoAMbZ8oY47tCy+3DYpYiInEIBMM4uX1hDcTSiG8OJyKSjABhnpUVRli6s0XUAEZl0FAATYHmils37ujnWlwy7FBGRkxQAE6ApUUcy5by2pyvsUkRETlIATIBl59UQMU0QIyKTiwJgAlSWFnHZvGo26M6gIjKJKAAmSFMizmt7uuhLDoZdiogIoACYMMsb4vQlU2ze1x12KSIigAJgwixvqAXgVX0cVEQmiZwCwMxWmtl2M9thZvcNs97M7KvB+jfNbFnGut3B5O+vm1lLRnvczF40s3eCx9r8HNLkVDejhItmz+Bvfrqb7zTvYWAwFXZJIlLgRgwAM4sCDwGrgCXArWa2JKvbKmBx8LMGeDhr/XXuvtTdGzPa7gNecvfFwEvB8rT2f3/zF5hbXcofPfMW193/QwWBiIQqlzOAJmCHu+90937gSWB1Vp/VwLc87WdAjZnNHeF1VwOPB88fB27Oveyp6YrzavmHO67hm59cTryimD965i2uf+CHPNW8V0EgIhMulwCYD+zNWG4N2nLt48D3zWyjma3J6DPb3dsBgsdZw+3czNaYWYuZtXR2duZQ7uRmZlx3ySyev+MaHvtkI7XlxXzumTe54YEf8VSLgkBEJk4uAWDDtPko+lzj7stIDxPdYWYfGkV9uPuj7t7o7o319fWj2XRSMzOuv2T2ySCoKS/ic08rCERk4uQSAK3AwozlBUBbrn3cfeixA3iO9JASwIGhYaLgsWO0xU8HmUHwjdsbqS5LB8FHvvQjvtuyl6SCQETGSS4B0AwsNrOEmRUDtwDrsvqsAz4RfBroKqDb3dvNrMLMKgHMrAL4FWBzxja3B89vB54f47FMaWbGDZfOZt2d6SCoKi3ivz/9JjcoCERknJh79mjOMJ3MbgQeBKLAY+7+52a2FsDdHzEzA/4SWAkcB37P3VvM7HzSf/UDxIC/d/c/D16zDngKOA/YA3zc3c/6IfnGxkZvaWk5W5dpw915aVsHD770czbv62FRXTmfvn4xNy+dRyyqr2+ISO7MbGPWpzDT7bkEwGRRSAEwREEgImOlAJji3J1/3dbBg//6c7a09dAQBMFqBYGIjEABME0oCERktBQA04y78+LWAzz4r++wtb2HxMwKPn39hdx0uYJARE6lAJimFAQiMhIFwDTn7nw/CIJt7T2cP7OCT99wIb/+CwoCkUKnACgQqZTz4rbTg+Cmy+cTjQz3hW0Rme4UAAUmlRo6I/g5b+8/wvkzK7jrhsX8+uXzFAQiBUYBUKBOC4L6Cu66XkEgUkjOFAAaHJ7mIhFj5QfmsP6ua3nkd5dRHI1wz3de5zcf/nd2HzwWdnkiEiIFQIFIB8Fc1t91LV/+z5ezs/MoN371ZZ5q3stUOgsUkfxRABSYSMT42BUL+N49H+LyBTV87pk3+W9/t4nDx/rDLk1EJpgCoEDNqynj27+/gj+58RJeevsA/+nBH/Pjn0/9CXdEJHcKgAIWiRhrPnQB/3DHNVSXFfGJxzbwP/9xC70Dg2GXJiITQAEgXDavmn/89C/xyV9s4Js/3c1Nf/kTtrX3hF2WiIwzBYAAUFoU5fM3Xcbf/N5yDh8fYPVf/pSvv7yTVEoXiEWmKwWAnOKXL57F9+6+lg9fXM///udt3PbYq7R3nwi7LBEZBwoAOU3djBIeve1KvvAbH2TTu12sfPBl/vnN9rDLEpE8UwDIsMyMW5rOY/3d19Iws4I7/n4Tn3nqDY70DoRdmojkiQJAzioxs4Kn117NXddfyHOvtXLjV1+mZfdZp24WkSkipwAws5Vmtt3MdpjZfcOsNzP7arD+TTNbFrQvNLMfmNk2M9tiZndnbPN5M9tnZq8HPzfm77Akn4qiEf7wVy7mu2uvBuC3//oVHvj+dgYGUyFXJiJjMWIAmFkUeAhYBSwBbjWzJVndVgGLg581wMNBexL4jLtfClwF3JG17ZfdfWnws35shyLj7cpFcdbfdS2/sWwBf/FvO/itR15hl+4nJDJl5XIG0ATscPed7t4PPAmszuqzGviWp/0MqDGzue7e7u6bANz9CLANmJ/H+mWCVZYWcf/HL+evfmcZuw8e48avvMwTG/bofkIiU1AuATAf2Jux3Mrpv8RH7GNmDcAVwKsZzXcGQ0aPmVltrkVL+G784FxeuOdDXLmolj9+9i3W/O1G3jvaF3ZZIjIKuQTAcDeNz/5z76x9zGwG8Axwj7sPfcX0YeACYCnQDjww7M7N1phZi5m1dHbqXjWTyZzqUr71X5r401+9lB9t72TlV17mh9s7wi5LRHKUSwC0AgszlhcAbbn2MbMi0r/8v+3uzw51cPcD7j7o7inga6SHmk7j7o+6e6O7N9bX1+dQrkykSMT4/WvPZ92nryFeXswnv9nMnz2/WfcTEpkCcgmAZmCxmSXMrBi4BViX1Wcd8Ing00BXAd3u3m5mBnwD2ObuX8rcwMzmZix+DNh8zkchobtkThXP33kNn/qlBI+/8i6/9hc/YUtbd9hlichZjBgA7p4E7gReIH0R9yl332Jma81sbdBtPbAT2EH6r/k/CNqvAW4Drh/m455fNLO3zOxN4Drg3rwdlYSitCjK//i1Jfztp5o40jvAzQ/9lL/+0X/ofkIik5TmBJZxcfhYP3/y3Fv8y+b9XHV+nC/99lLm1ZSFXZZIQdKcwDKhaiuK+avfWcb/+61f4K3WblY++GPWvZF96UhEwqQAkHFjZny8cSHr776WC2fN4K4nXuPe77xOj+4nJDIpKABk3C2qq+Cp/3o1937kIta90caqB19mwy7dT0gkbAoAmRCxaIS7P7KY7669mljUuOXRV/ji995mX9cJfYtYJCS6CCwT7lhfkv/1j1v5Tkv6y+M15UUsmVvFZfOqWDKvisvmVXP+zApiUf19IpIPZ7oIrACQ0Gze181re7vY2tbD1rZu3t5/hL5k+g6jJbEIl8ypZMm8KpbMrWLJvGounVtJeXEs5KpFpp4zBYD+NUloPjC/mg/Mrz65nBxMsfPgMba29bClrZut7T38y+b9PLEhfaZglp6fIH22UB2cLVQxc0ZJWIcgMqUpAGTSiEUjXDS7kotmV3LzFel7Cbo77d29QSj0sLW9m9f3dvFPGVNUzqosORkGS+ZWc9m8Ks6LlxOJDHeLKhEZogCQSc3MmFdTxryaMj6yZPbJ9u4TA+mho/bgbKGth5+8c5Bk8K3jGSUxLp1bGQwfpc8YFs+eQUksGtahiEw6CgCZkqrLirj6gjquvqDuZFtfcpB3Dhw9ZQjp6Y2tHHslfWO6WMS4cNaMk4EwFA7VZUVhHYZIqBQAMm2UxKIZ1xXSN6dNpZw9h46fdqbw7KZ9J7ebX1PGnOpSZleVMKuylPrKEmZVljC7qpRZQVtteRHpexuKTB8KAJnWIhGjYWYFDTMruPGD79+AtvNIH1vbe9ja1sPPDxxhf3cv2/cf4eV3DnKkN3na6xRF7fRwqCw5GRBDj3UVxbr2IFOGAkAKUn1lCR+urOfDF50+x8SJ/kE6jvTScaSPjp4+DvQEz4/00nmkj93vHWPD7kN0HT/9lhbRiDFzRvHJgKivfP/MYigwZlelg0Lfc5CwKQBEspQVR1lUV8Giuoqz9usdGKTzSB8dR/roDALjQE8vHT3pttbDJ3htTxfvHes/bVszqKsYOptIB8TsqhLmVJcxt6aUedXpYamq0piGnmTcKABEzlFpUZSF8XIWxsvP2m9gMMXBo30c6OmjY+hs4uRZRfrMYnNbDweP9pH9vcyK4ihza8qYW13K3OpS5lSXMa+69JS2ylJdxJZzowAQGWdF0Qhzq8uYW332+RAGBlN0HOljf/cJ2rp62d/dS1v3Cdq7emnv6WX7/k46hwmJypIYc4ZCoar0lDOIeTXp0JhRon/qcjr9XyEySRRFI8yvKWN+TRlXLhq+z8BgigM9vbR3Bz9dJ4Ln6cdt7T10Huk7bbvK0tipoVBVdlpQ6DYbhUf/xUWmkKJohAW15SyoPfOwU38yMyROnAyKtu70WcWWtm4OHj39ukRVaYx5NWXUzSimrChGeXGU8uIopUXRk8/Lit9vLyuKUl4co6w4ckr/suJ0e1Sfhpr0FAAi00xxLDLitYm+5CAHuvto6z5xcqhpf3cvbV29HD7ez6FjJzjRn+R4/yAn+gc5PjDI4Cjndi6ORYKQGAqFKOVFsZPPy4rebx8uWEpiEYpiEYoiln6MRiiKGsXRCLGM50XRdL9YJL2sj+HmTgEgUoBKYlHOqyvnvLqzX8Ae4u4MDHoQBhnB0D/I8f4kvQNDzzPaB5Inn58YGGpP0nW8n7au99vT26fydmzRiFEUtSAwIiefD4VFLHM5ZsQi6fbi2OnbDPUvjkbS/WJGUeT91xjqF4sGQZXZ/5T1Qf9I5j4z1kXCCa6cAsDMVgJfAaLA1939C1nrLVh/I3Ac+KS7bzrbtmYWB74DNAC7gd9298NjPyQRyTczozhmFMciVJP/Tx2lUk5v8tQA6U+m6B9MMRD8JAf9lOWBpDOQSjGQTDGQsS456AwMZmw71G/Qg77pdclBp28gxdHBJP2DTvLka2fsJ5liIJV+vfG+c340YifPYmJZAVQUjfB/PvZBmhLxvO5zxAAwsyjwEPBRoBVoNrN17r41o9sqYHHwswJ4GFgxwrb3AS+5+xfM7L5g+Y/yd2giMlVEIkZ5cWxSX4geDIIgM2QGUqcGx9Bjcmg5CKhkKnvd+/2TWa87FE7JVIr+ZPpxYDBFRUn+b2SYy7vdBOxw950AZvYksBrIDIDVwLc8PbvMz8ysxszmkv7r/kzbrgZ+Odj+ceCHKABEZJKKRoxoJH1RfLrI5bvo84G9GcutQVsufc627Wx3bwcIHmcNt3MzW2NmLWbW0tnZmUO5IiKSi1wCYLgrE9mjYWfqk8u2Z+Xuj7p7o7s31tefft8WERE5N7kEQCtD99ZNWwC05djnbNseCIaJCB47ci9bRETGKpcAaAYWm1nCzIqBW4B1WX3WAZ+wtKuA7mBY52zbrgNuD57fDjw/xmMREZFRGPEisLsnzexO4AXSH+V8zN23mNnaYP0jwHrSHwHdQfpjoL93tm2Dl/4C8JSZfQrYA3w8r0cmIiJnZT7eH27No8bGRm9paQm7DBGRKcXMNrp7Y3a7ZqQQESlQCgARkQI1pYaAzKwTeDfsOsZoJnAw7CImEb0f79N7cSq9H6cay/uxyN1P+xz9lAqA6cDMWoYbiytUej/ep/fiVHo/TjUe74eGgERECpQCQESkQCkAJt6jYRcwyej9eJ/ei1Pp/ThV3t8PXQMQESlQOgMQESlQCgARkQKlAJggZrbQzH5gZtvMbIuZ3R12TWEzs6iZvWZm/xR2LWELJlF62szeDv4fuTrsmsJiZvcG/0Y2m9kTZlYadk0TycweM7MOM9uc0RY3sxfN7J3gsTYf+1IATJwk8Bl3vxS4CrjDzJaEXFPY7ga2hV3EJPEV4HvufglwOQX6vpjZfOAuoNHdP0D6JpK3hFvVhPsbYGVW29AUuouBl4LlMVMATBB3b3f3TcHzI6T/gWfPrFYwzGwB8KvA18OuJWxmVgV8CPgGgLv3u3tXqEWFKwaUmVkMKOf0+UemNXf/MXAoq3k16alzCR5vzse+FAAhMLMG4Arg1ZBLCdODwOeAVMh1TAbnA53AN4Mhsa+bWUXYRYXB3fcB95O+RXw76blFvh9uVZNCTlPojpYCYIKZ2QzgGeAed+8Ju54wmNmvAR3uvjHsWiaJGLAMeNjdrwCOkadT/KkmGNteDSSAeUCFmf1uuFVNXwqACWRmRaR/+X/b3Z8Nu54QXQPcZGa7gSeB683s78ItKVStQKu7D50RPk06EArRR4Bd7t7p7gPAs8AvhlzTZDAuU+gqACaImRnpMd5t7v6lsOsJk7v/sbsvcPcG0hf4/s3dC/avPHffD+w1s4uDphuArSGWFKY9wFVmVh78m7mBAr0gnmVcptAdcUpIyZtrgNuAt8zs9aDtT9x9fXglySTyaeDbwdzZOwmmVS007v6qmT0NbCL9ybnXKLBbQpjZE8AvAzPNrBX4M8ZpCl3dCkJEpEBpCEhEpEApAERECpQCQESkQCkAREQKlAJARKRAKQBERAqUAkBEpED9fynd73yOe4WLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a,losses)\n",
    "print(\"Cost v/s Epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e43ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is : \n",
      "\n",
      "Got 54989 / 55000 correct (99.98)\n",
      "The validation accuracy is : \n",
      "\n",
      "Got 4969 / 5000 correct (99.38)\n",
      "The testing accuracy is : \n",
      "\n",
      "Got 9929 / 10000 correct (99.29)\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is : \\n\")\n",
    "check_accuracy_part(train_loader,model)\n",
    "print(\"The validation accuracy is : \\n\")\n",
    "check_accuracy_part(val_loader,model)\n",
    "print(\"The testing accuracy is : \\n\")\n",
    "check_accuracy_part(test_loader,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
