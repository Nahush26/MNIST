{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973ab55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266591ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is GeForce 940MX\n",
      "\n",
      " cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if(torch.cuda.is_available()):\n",
    "  print(\"The device is \" + torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"Using cpu no gpu available\")\n",
    "print('\\n',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbbc229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leleg\\anaconda3\\envs\\pytorchml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train = True ,download =  False, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307, ), (0.3081, ))]))\n",
    "test = datasets.MNIST(\"\",train = False ,download = False, transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307, ), (0.3081, ))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0de8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846252d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split,DataLoader\n",
    "train,val = random_split(train, [55000,5000])\n",
    "train_loader = DataLoader(train,batch_size = 64)\n",
    "val_loader = DataLoader(val,batch_size = 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9081b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eb4fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for (x,y) in train_loader:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65c10722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9503c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bddad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6439a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipper(nn.Module):\n",
    "    def __init__(self,width):\n",
    "        super(skipper,self).__init__()\n",
    "        #making a res block using sequential inside module hehe\n",
    "        self.resb1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = width[0] , \n",
    "                  out_channels = width[1], \n",
    "                  kernel_size= (3,3),\n",
    "                  stride = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels = width[1],\n",
    "                  out_channels = width[2],\n",
    "                  kernel_size = (3,3),\n",
    "                  stride = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[2]),\n",
    "        nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "                  \n",
    "        )\n",
    "        self.skip = nn.Sequential(\n",
    "        nn.Conv2d(in_channels = width[0],\n",
    "                  out_channels = width[2],\n",
    "                  kernel_size = (1,1),\n",
    "                  padding = 'same',\n",
    "                  bias = True\n",
    "                 ),\n",
    "        nn.BatchNorm2d(width[2]),\n",
    "        nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        #cut = x\n",
    "        out1 = self.resb1(x)\n",
    "        #print(out1.shape)\n",
    "        out2 = self.skip(x)\n",
    "        x = F.relu(out1+out2)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f8ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network,self).__init__()\n",
    "        self.block1 =  skipper(width= [1,16,32])\n",
    "        #self.reduce = nn.MaxPool2d(kernel_size = (2,2),stride = (2,2),padding = 0)\n",
    "        self.block2 =  skipper(width= [32,64,128])\n",
    "        self.fc1    =  nn.Linear(128*7*7,200)\n",
    "        self.fc2    =  nn.Linear(200,10)\n",
    "        #self.bn1    =  nn.BatchNorm1d(200)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.block1(x)\n",
    "        #print(out.shape)\n",
    "        #out = self.reduce(out)\n",
    "        out = self.block2(out)\n",
    "        #out = self.reduce(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        #out = self.bn1(out)\n",
    "        score = self.fc2(out)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7871807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part(loader, model):\n",
    "    print(\"VAL/TEST accuracy : \")   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec4136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part(model, optimizer,scheduler_f, epochs=1):\n",
    "    losses =[]\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        avg = 0\n",
    "        i = 0\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            #scores = scores.reshape(y.shape[1])\n",
    "            #print(scores.shape,x.shape,y.shape)\n",
    "            #break\n",
    "            loss = metric(scores, y)\n",
    "           \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "            loss.backward()\n",
    "             \n",
    "        \n",
    "            optimizer.step()\n",
    "            #scheduler_f.step()\n",
    "            avg+=float(loss)\n",
    "            i+=1\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part(val_loader, model)\n",
    "                print()\n",
    "        scheduler_f.step()\n",
    "        print('Epoch-{0} lr: {1}'.format(e, optimizer.param_groups[0]['lr']))\n",
    "        losses.append(avg/i)\n",
    "    #return losses\n",
    "        #break\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d637033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-2           [-1, 16, 28, 28]              32\n",
      "              ReLU-3           [-1, 16, 28, 28]               0\n",
      "            Conv2d-4           [-1, 32, 28, 28]           4,640\n",
      "       BatchNorm2d-5           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-6           [-1, 32, 14, 14]               0\n",
      "            Conv2d-7           [-1, 32, 28, 28]              64\n",
      "       BatchNorm2d-8           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-9           [-1, 32, 14, 14]               0\n",
      "          skipper-10           [-1, 32, 14, 14]               0\n",
      "           Conv2d-11           [-1, 64, 14, 14]          18,496\n",
      "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
      "             ReLU-13           [-1, 64, 14, 14]               0\n",
      "           Conv2d-14          [-1, 128, 14, 14]          73,856\n",
      "      BatchNorm2d-15          [-1, 128, 14, 14]             256\n",
      "        MaxPool2d-16            [-1, 128, 7, 7]               0\n",
      "           Conv2d-17          [-1, 128, 14, 14]           4,224\n",
      "      BatchNorm2d-18          [-1, 128, 14, 14]             256\n",
      "        MaxPool2d-19            [-1, 128, 7, 7]               0\n",
      "          skipper-20            [-1, 128, 7, 7]               0\n",
      "           Linear-21                  [-1, 200]       1,254,600\n",
      "           Linear-22                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 1,358,850\n",
      "Trainable params: 1,358,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.39\n",
      "Params size (MB): 5.18\n",
      "Estimated Total Size (MB): 7.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = network()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size = 3,gamma = 0.3)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82888226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.3243\n",
      "VAL/TEST accuracy : \n",
      "Got 536 / 5000 correct (10.72)\n",
      "\n",
      "Iteration 100, loss = 0.1720\n",
      "VAL/TEST accuracy : \n",
      "Got 4748 / 5000 correct (94.96)\n",
      "\n",
      "Iteration 200, loss = 0.0773\n",
      "VAL/TEST accuracy : \n",
      "Got 4825 / 5000 correct (96.50)\n",
      "\n",
      "Iteration 300, loss = 0.1228\n",
      "VAL/TEST accuracy : \n",
      "Got 4815 / 5000 correct (96.30)\n",
      "\n",
      "Iteration 400, loss = 0.0459\n",
      "VAL/TEST accuracy : \n",
      "Got 4868 / 5000 correct (97.36)\n",
      "\n",
      "Iteration 500, loss = 0.0937\n",
      "VAL/TEST accuracy : \n",
      "Got 4905 / 5000 correct (98.10)\n",
      "\n",
      "Iteration 600, loss = 0.0745\n",
      "VAL/TEST accuracy : \n",
      "Got 4900 / 5000 correct (98.00)\n",
      "\n",
      "Iteration 700, loss = 0.0445\n",
      "VAL/TEST accuracy : \n",
      "Got 4825 / 5000 correct (96.50)\n",
      "\n",
      "Iteration 800, loss = 0.0850\n",
      "VAL/TEST accuracy : \n",
      "Got 4876 / 5000 correct (97.52)\n",
      "\n",
      "Epoch-0 lr: 0.001\n",
      "Iteration 0, loss = 0.1698\n",
      "VAL/TEST accuracy : \n",
      "Got 4893 / 5000 correct (97.86)\n",
      "\n",
      "Iteration 100, loss = 0.0378\n",
      "VAL/TEST accuracy : \n",
      "Got 4922 / 5000 correct (98.44)\n",
      "\n",
      "Iteration 200, loss = 0.0495\n",
      "VAL/TEST accuracy : \n",
      "Got 4902 / 5000 correct (98.04)\n",
      "\n",
      "Iteration 300, loss = 0.0288\n",
      "VAL/TEST accuracy : \n",
      "Got 4942 / 5000 correct (98.84)\n",
      "\n",
      "Iteration 400, loss = 0.0298\n",
      "VAL/TEST accuracy : \n",
      "Got 4928 / 5000 correct (98.56)\n",
      "\n",
      "Iteration 500, loss = 0.0588\n",
      "VAL/TEST accuracy : \n",
      "Got 4911 / 5000 correct (98.22)\n",
      "\n",
      "Iteration 600, loss = 0.1190\n",
      "VAL/TEST accuracy : \n",
      "Got 4925 / 5000 correct (98.50)\n",
      "\n",
      "Iteration 700, loss = 0.0281\n",
      "VAL/TEST accuracy : \n",
      "Got 4935 / 5000 correct (98.70)\n",
      "\n",
      "Iteration 800, loss = 0.0278\n",
      "VAL/TEST accuracy : \n",
      "Got 4916 / 5000 correct (98.32)\n",
      "\n",
      "Epoch-1 lr: 0.001\n",
      "Iteration 0, loss = 0.0457\n",
      "VAL/TEST accuracy : \n",
      "Got 4931 / 5000 correct (98.62)\n",
      "\n",
      "Iteration 100, loss = 0.0181\n",
      "VAL/TEST accuracy : \n",
      "Got 4922 / 5000 correct (98.44)\n",
      "\n",
      "Iteration 200, loss = 0.0797\n",
      "VAL/TEST accuracy : \n",
      "Got 4934 / 5000 correct (98.68)\n",
      "\n",
      "Iteration 300, loss = 0.0101\n",
      "VAL/TEST accuracy : \n",
      "Got 4940 / 5000 correct (98.80)\n",
      "\n",
      "Iteration 400, loss = 0.0369\n",
      "VAL/TEST accuracy : \n",
      "Got 4933 / 5000 correct (98.66)\n",
      "\n",
      "Iteration 500, loss = 0.0342\n",
      "VAL/TEST accuracy : \n",
      "Got 4931 / 5000 correct (98.62)\n",
      "\n",
      "Iteration 600, loss = 0.0772\n",
      "VAL/TEST accuracy : \n",
      "Got 4944 / 5000 correct (98.88)\n",
      "\n",
      "Iteration 700, loss = 0.0329\n",
      "VAL/TEST accuracy : \n",
      "Got 4950 / 5000 correct (99.00)\n",
      "\n",
      "Iteration 800, loss = 0.0209\n",
      "VAL/TEST accuracy : \n",
      "Got 4946 / 5000 correct (98.92)\n",
      "\n",
      "Epoch-2 lr: 0.0003\n",
      "Iteration 0, loss = 0.0731\n",
      "VAL/TEST accuracy : \n",
      "Got 4921 / 5000 correct (98.42)\n",
      "\n",
      "Iteration 100, loss = 0.0028\n",
      "VAL/TEST accuracy : \n",
      "Got 4957 / 5000 correct (99.14)\n",
      "\n",
      "Iteration 200, loss = 0.0012\n",
      "VAL/TEST accuracy : \n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 300, loss = 0.0092\n",
      "VAL/TEST accuracy : \n",
      "Got 4963 / 5000 correct (99.26)\n",
      "\n",
      "Iteration 400, loss = 0.0030\n",
      "VAL/TEST accuracy : \n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 500, loss = 0.0058\n",
      "VAL/TEST accuracy : \n",
      "Got 4958 / 5000 correct (99.16)\n",
      "\n",
      "Iteration 600, loss = 0.0186\n",
      "VAL/TEST accuracy : \n",
      "Got 4959 / 5000 correct (99.18)\n",
      "\n",
      "Iteration 700, loss = 0.0039\n",
      "VAL/TEST accuracy : \n",
      "Got 4956 / 5000 correct (99.12)\n",
      "\n",
      "Iteration 800, loss = 0.0051\n",
      "VAL/TEST accuracy : \n",
      "Got 4963 / 5000 correct (99.26)\n",
      "\n",
      "Epoch-3 lr: 0.0003\n",
      "Iteration 0, loss = 0.0652\n",
      "VAL/TEST accuracy : \n",
      "Got 4962 / 5000 correct (99.24)\n",
      "\n",
      "Iteration 100, loss = 0.0013\n",
      "VAL/TEST accuracy : \n",
      "Got 4961 / 5000 correct (99.22)\n",
      "\n",
      "Iteration 200, loss = 0.0012\n",
      "VAL/TEST accuracy : \n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 300, loss = 0.0036\n",
      "VAL/TEST accuracy : \n",
      "Got 4966 / 5000 correct (99.32)\n",
      "\n",
      "Iteration 400, loss = 0.0017\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 500, loss = 0.0027\n",
      "VAL/TEST accuracy : \n",
      "Got 4965 / 5000 correct (99.30)\n",
      "\n",
      "Iteration 600, loss = 0.0118\n",
      "VAL/TEST accuracy : \n",
      "Got 4959 / 5000 correct (99.18)\n",
      "\n",
      "Iteration 700, loss = 0.0037\n",
      "VAL/TEST accuracy : \n",
      "Got 4959 / 5000 correct (99.18)\n",
      "\n",
      "Iteration 800, loss = 0.0038\n",
      "VAL/TEST accuracy : \n",
      "Got 4968 / 5000 correct (99.36)\n",
      "\n",
      "Epoch-4 lr: 0.0003\n",
      "Iteration 0, loss = 0.0451\n",
      "VAL/TEST accuracy : \n",
      "Got 4966 / 5000 correct (99.32)\n",
      "\n",
      "Iteration 100, loss = 0.0010\n",
      "VAL/TEST accuracy : \n",
      "Got 4959 / 5000 correct (99.18)\n",
      "\n",
      "Iteration 200, loss = 0.0010\n",
      "VAL/TEST accuracy : \n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 300, loss = 0.0045\n",
      "VAL/TEST accuracy : \n",
      "Got 4969 / 5000 correct (99.38)\n",
      "\n",
      "Iteration 400, loss = 0.0025\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 500, loss = 0.0030\n",
      "VAL/TEST accuracy : \n",
      "Got 4964 / 5000 correct (99.28)\n",
      "\n",
      "Iteration 600, loss = 0.0064\n",
      "VAL/TEST accuracy : \n",
      "Got 4962 / 5000 correct (99.24)\n",
      "\n",
      "Iteration 700, loss = 0.0123\n",
      "VAL/TEST accuracy : \n",
      "Got 4952 / 5000 correct (99.04)\n",
      "\n",
      "Iteration 800, loss = 0.0024\n",
      "VAL/TEST accuracy : \n",
      "Got 4963 / 5000 correct (99.26)\n",
      "\n",
      "Epoch-5 lr: 8.999999999999999e-05\n",
      "Iteration 0, loss = 0.0120\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 100, loss = 0.0007\n",
      "VAL/TEST accuracy : \n",
      "Got 4962 / 5000 correct (99.24)\n",
      "\n",
      "Iteration 200, loss = 0.0002\n",
      "VAL/TEST accuracy : \n",
      "Got 4974 / 5000 correct (99.48)\n",
      "\n",
      "Iteration 300, loss = 0.0008\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 400, loss = 0.0017\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 500, loss = 0.0032\n",
      "VAL/TEST accuracy : \n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Iteration 600, loss = 0.0057\n",
      "VAL/TEST accuracy : \n",
      "Got 4971 / 5000 correct (99.42)\n",
      "\n",
      "Iteration 700, loss = 0.0008\n",
      "VAL/TEST accuracy : \n",
      "Got 4978 / 5000 correct (99.56)\n",
      "\n",
      "Iteration 800, loss = 0.0010\n",
      "VAL/TEST accuracy : \n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Epoch-6 lr: 8.999999999999999e-05\n",
      "Iteration 0, loss = 0.0057\n",
      "VAL/TEST accuracy : \n",
      "Got 4975 / 5000 correct (99.50)\n",
      "\n",
      "Iteration 100, loss = 0.0005\n",
      "VAL/TEST accuracy : \n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 200, loss = 0.0001\n",
      "VAL/TEST accuracy : \n",
      "Got 4972 / 5000 correct (99.44)\n",
      "\n",
      "Iteration 300, loss = 0.0007\n",
      "VAL/TEST accuracy : \n",
      "Got 4974 / 5000 correct (99.48)\n",
      "\n",
      "Iteration 400, loss = 0.0013\n",
      "VAL/TEST accuracy : \n",
      "Got 4968 / 5000 correct (99.36)\n",
      "\n",
      "Iteration 500, loss = 0.0010\n",
      "VAL/TEST accuracy : \n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 600, loss = 0.0037\n",
      "VAL/TEST accuracy : \n",
      "Got 4970 / 5000 correct (99.40)\n",
      "\n",
      "Iteration 700, loss = 0.0006\n",
      "VAL/TEST accuracy : \n",
      "Got 4978 / 5000 correct (99.56)\n",
      "\n",
      "Iteration 800, loss = 0.0007\n",
      "VAL/TEST accuracy : \n",
      "Got 4973 / 5000 correct (99.46)\n",
      "\n",
      "Epoch-7 lr: 8.999999999999999e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "losses = train_part(model, optimizer,scheduler_f = scheduler,epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d339c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e43ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL/TEST accuracy : \n",
      "Got 54978 / 55000 correct (99.96)\n"
     ]
    }
   ],
   "source": [
    "check_accuracy_part(train_loader,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44751e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281874d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3,2,2))\n",
    "b = torch.rot90(a,-1,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a,'\\n\\n\\n',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,d  = torch.utils.data.random_split(range(10), [3, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1501c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(c)):\n",
    "    print(c[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98290c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
